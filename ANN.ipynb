{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "name": "ANN.ipynb",
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCXLXJ9CnW09"
      },
      "outputs": [],
      "source": [
        "# Importing the TensorFlow library, which is used for building and Nerul network and DL ML models\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing the Matplotlib library, which is used for creating graphs and plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing specific parts from the TensorFlow Keras module\n",
        "# 'models' helps in creating and managing Nerual Network models\n",
        "# 'layers' helps in creating different layers of the Deep learining Model  models\n",
        "from tensorflow.keras import models, layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the CIFAR-10 dataset from the TensorFlow Keras library\n",
        "# The dataset contains 60,000 32x32 color images in 10 classes, with 6,000 images per class\n",
        "# It is divided into 50,000 training images and 10,000 test images\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# X_train and Y_train are the training data and labels (used to train the model)\n",
        "# X_test and Y_test are the test data and labels (used to test the model's performance)\n"
      ],
      "metadata": {
        "id": "rLWwHy0BqN65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the training data and labels\n",
        "print(\"Shape of X_train (training data):\", X_train.shape)\n",
        "print(\"Shape of Y_train (training labels):\", Y_train.shape)\n",
        "\n",
        "# Print the shape of the test data and labels\n",
        "print(\"Shape of X_test (test data):\", X_test.shape)\n",
        "print(\"Shape of Y_test (test labels):\", Y_test.shape)\n"
      ],
      "metadata": {
        "id": "6r0OO3xrsMGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the training and test images to a range of 0 to 1\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n"
      ],
      "metadata": {
        "id": "BNX7YV9rs73U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class names for the CIFAR-10 dataset\n",
        "# Each class represents a different category of images in the dataset\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ],
      "metadata": {
        "id": "sruYfeCNuueW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HRiSqNswe-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an Artificial Neural Network (ANN) using TensorFlow Keras\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add the first layer (Flatten) to convert the 2D image data into 1D\n",
        "model.add(layers.Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# Add the first hidden layer with 128 neurons and ReLU activation function\n",
        "model.add(layers.Dense(700, activation='relu'))\n",
        "\n",
        "# Add the second hidden layer with 64 neurons and ReLU activation function\n",
        "model.add(layers.Dense(500, activation='relu'))\n",
        "\n",
        "\n",
        "# Add the second hidden layer with 64 neurons and ReLU activation function\n",
        "model.add(layers.Dense(600, activation='relu'))\n",
        "\n",
        "# Add the second hidden layer with 64 neurons and ReLU activation function\n",
        "model.add(layers.Dense(400, activation='relu'))\n",
        "\n",
        "# Add the output layer with 10 neurons (one for each class) and softmax activation function\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Ex6ZrHwEwHmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with specific settings\n",
        "model.compile(\n",
        "    optimizer='adam',               # Use the Adam optimizer, which is a popular choice for training neural networks\n",
        "    loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy as the loss function, suitable for classification tasks\n",
        "    metrics=['accuracy']            # Track the accuracy metric during training\n",
        ")\n",
        "\n",
        "# Print a message indicating that the model has been compiled\n",
        "print(\"Model compilation is complete.\")\n"
      ],
      "metadata": {
        "id": "-YqmX9csxPqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,                          # Training data (input features)\n",
        "    Y_train,                          # Training labels (true outputs)\n",
        "    epochs=10,                        # Number of epochs (passes through the entire training dataset)\n",
        "    batch_size=100,                    # Custom batch size for training\n",
        "    validation_data=(X_test, Y_test)  # Validation data to evaluate the model's performance after each epoch\n",
        ")"
      ],
      "metadata": {
        "id": "uxM-ndqoxhdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "vL1WNwkoyiRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Access the accuracy values from the training history\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Get the number of epochs\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "# Plotting the accuracy\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "soT6LYjw_T5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}